{
	"common": {
		"save": "Save",
		"done": "Done",
		"cancel": "Cancel",
		"reset": "Reset",
		"select": "Select",
		"add": "Add",
		"remove": "Remove"
	},
	"header": {
		"title": "Settings",
		"saveButtonTooltip": "Save changes",
		"nothingChangedTooltip": "No changes",
		"doneButtonTooltip": "Discard unsaved changes and close settings panel"
	},
	"unsavedChangesDialog": {
		"title": "Unsaved Changes",
		"description": "Do you want to discard changes and continue?",
		"cancelButton": "Cancel",
		"discardButton": "Discard Changes"
	},
	"sections": {
		"providers": "Providers",
		"autoApprove": "Auto Approve",
		"browser": "Computer Access",
		"checkpoints": "Checkpoints",
		"notifications": "Notifications",
		"contextManagement": "Context",
		"terminal": "Terminal",
		"prompts": "Prompts",
		"experimental": "Experimental",
		"language": "Language",
		"about": "About Researcherry"
	},
	"prompts": {
		"description": "Configure support prompts used for quick actions like prompt improvement, code explanation, and issue fixing. These prompts help Researcherry provide better support for common development tasks."
	},
	"providers": {
		"apiProvider": "API Provider",
		"providerDocumentation": "Provider Documentation",
		"anthropicApiKey": "Anthropic API Key",
		"apiKeyStorageNotice": "Your API key is stored locally and never sent to our servers.",
		"getAnthropicApiKey": "Get Anthropic API Key",
		"useCustomBaseUrl": "Use custom base URL",
		"model": "Model",
		"validation": {
			"apiKey": "API key is required"
		},
		"placeholders": {
			"apiKey": "Enter your API key"
		}
	},
	"importSettings": "Import Settings",
	"autoApprove": {
		"description": "Allow Researcherry to perform certain actions automatically without asking for approval.",
		"toggleAriaLabel": "Toggle auto-approve",
		"disabledAriaLabel": "Auto-approve is disabled â€“ select options first",
		"readOnly": {
			"label": "Read",
			"description": "Automatically read files and folders without approval.",
			"outsideWorkspace": {
				"label": "Including outside workspace",
				"description": "Allow reading files outside the current workspace without approval."
			}
		},
		"write": {
			"label": "Write",
			"description": "Automatically create and edit files without approval.",
			"delayLabel": "Delay after write for diagnostics",
			"outsideWorkspace": {
				"label": "Including outside workspace",
				"description": "Allow creating and editing files outside the current workspace without approval."
			},
			"protected": {
				"label": "Include protected files",
				"description": "Allow creating and editing protected files (like .neiraignore and .neira config files) without approval."
			}
		},
		"browser": {
			"label": "Browser",
			"description": "Automatically perform allowed browser actions when the model supports computer use."
		},
		"retry": {
			"label": "Retry",
			"description": "Automatically retry API requests on server errors.",
			"delayLabel": "Delay before retry"
		},
		"mcp": {
			"label": "MCP",
			"description": "Enable auto-approve of specific MCP tools in the MCP Servers view (requires both this option and the tool's 'Always allow' checkbox)."
		},
		"modeSwitch": { "label": "Mode", "description": "Automatically switch between modes without approval." },
		"subtasks": { "label": "Subtasks", "description": "Allow creating and executing subtasks without approval." },
		"followupQuestions": {
			"label": "Follow-up",
			"description": "Automatically pick the first suggested answer after a timeout.",
			"timeoutLabel": "Timeout before automatically selecting the first answer"
		},
		"execute": {
			"label": "Execute",
			"description": "Automatically execute allowed terminal commands without approval.",
			"allowedCommands": "Allowed commands",
			"allowedCommandsDescription": "Command prefixes that can be executed automatically when 'Always allow execute' is enabled. Add * to allow all commands (use with caution).",
			"deniedCommands": "Denied commands",
			"deniedCommandsDescription": "Command prefixes that will be automatically denied without asking. When there is overlap, the longest matching prefix wins. Add * to deny all commands.",
			"commandPlaceholder": "Enter a command prefix (e.g., 'git ')",
			"deniedCommandPlaceholder": "Enter a command prefix to deny (e.g., 'rm -rf')",
			"addButton": "Add",
			"autoDenied": "Commands with prefix `{{prefix}}` were denied by the user. Do not bypass this by running a different command."
		},
		"updateTodoList": { "label": "Todo", "description": "Todo list updates automatically without approval" },
		"apiRequestLimit": {
			"title": "Max requests",
			"description": "Automatically perform up to this many API requests before asking for approval to continue the task.",
			"unlimited": "Unlimited"
		},
		"selectOptionsFirst": "Select at least one option below to enable auto-approve",
		"apiCostLimit": { "title": "Max cost", "unlimited": "Unlimited" },
		"maxLimits": {
			"description": "Automatically proceed until the limits below are reached before requesting approval."
		}
	},
	"browser": {
		"enable": {
			"label": "Enable browser tool",
			"description": "If enabled, Researcherry can use a browser when using models that support computer use. <0>Learn more</0>"
		},
		"viewport": {
			"label": "Viewport size",
			"description": "Choose a viewport size for browser interactions.",
			"options": {
				"largeDesktop": "Large desktop (1280x800)",
				"smallDesktop": "Small desktop (900x600)",
				"tablet": "Tablet (768x1024)",
				"mobile": "Mobile (360x640)"
			}
		},
		"screenshotQuality": {
			"label": "Screenshot quality",
			"description": "Adjust WebP quality for browser screenshots. Higher values are clearer but cost more tokens."
		},
		"remote": {
			"label": "Use remote browser connection",
			"description": "Connect to Chrome with remote debugging enabled (--remote-debugging-port=9222).",
			"urlPlaceholder": "Custom URL (e.g., http://localhost:9222)",
			"testButton": "Test connection",
			"testingButton": "Testing...",
			"instructions": "Enter a DevTools Protocol address or leave empty to auto-discover local Chrome instances."
		}
	},
	"contextManagement": {
		"description": "Control what information is included in the AI context window.",
		"openTabs": {
			"label": "Open tabs context limit",
			"description": "Maximum number of VS Code tabs to include in context."
		},
		"workspaceFiles": {
			"label": "Workspace files context limit",
			"description": "Maximum number of files from the current directory details to include."
		},
		"maxConcurrentFileReads": {
			"label": "Max concurrent file reads",
			"description": "Maximum concurrent files the read_file tool can process."
		},
		"rsignore": {
			"label": "Show .neiraignore files in lists and search",
			"description": "If enabled, files matching .neiraignore are shown with a lock icon; if disabled, they are hidden."
		},
		"maxReadFile": {
			"label": "Auto-truncation threshold when reading file",
			"lines": "lines",
			"always_full_read": "Always read the whole file",
			"description": "Default number of lines to read when start/end is not specified. -1 = read whole file; 0 = create minimal index only."
		},
		"maxImageFileSize": {
			"label": "Max image file size",
			"mb": "MB",
			"description": "Maximum size (MB) for image files processed by the read_file tool."
		},
		"maxTotalImageSize": {
			"label": "Max total image size",
			"mb": "MB",
			"description": "Cumulative size (MB) limit for all images processed in one read_file operation."
		},
		"diagnostics": {
			"includeMessages": {
				"label": "Automatically include diagnostics in context",
				"description": "When enabled, diagnostic messages from edited files are included automatically."
			},
			"maxMessages": {
				"label": "Max diagnostic messages",
				"description": "Maximum number of diagnostic messages to include.",
				"resetTooltip": "Reset to default (50)",
				"unlimited": "Unlimited diagnostic messages",
				"unlimitedLabel": "Unlimited"
			},
			"delayAfterWrite": {
				"label": "Delay after write so diagnostics can detect issues",
				"description": "Wait time after writing files before proceeding."
			}
		},
		"autoCondenseContext": { "name": "Automatically run intelligent context condensing" },
		"condensingThreshold": {
			"label": "Condensing threshold",
			"selectProfile": "Select profile for threshold",
			"defaultProfile": "Global default (all profiles)",
			"defaultDescription": "When context reaches this percent, it will be condensed automatically for all profiles without custom thresholds.",
			"profileDescription": "Custom threshold for this profile (overrides global default)",
			"usesGlobal": "(uses global {{threshold}}%)"
		}
	},
	"terminal": {
		"basic": { "label": "Terminal settings: Basic", "description": "Basic terminal settings" },
		"advanced": {
			"label": "Terminal settings: Advanced",
			"description": "Some options may require restarting the terminal."
		},
		"outputLineLimit": {
			"label": "Terminal output line limit",
			"description": "Maximum number of lines to include in terminal output. <0>Learn more</0>"
		},
		"outputCharacterLimit": {
			"label": "Terminal output character limit",
			"description": "Maximum number of characters to include in terminal output. <0>Learn more</0>"
		},
		"compressProgressBar": {
			"label": "Compress progress bar output",
			"description": "Collapse carriage-return progress output to final state. <0>Learn more</0>"
		},
		"inheritEnv": {
			"label": "Inherit environment variables",
			"description": "Toggle VS Code setting terminal.integrated.inheritEnv. <0>Learn more</0>"
		},
		"shellIntegrationDisabled": {
			"label": "Disable terminal shell integration",
			"description": "Use a simpler execution method as a fallback. <0>Learn more</0>"
		},
		"shellIntegrationTimeout": {
			"label": "Terminal shell integration timeout",
			"description": "Maximum wait time for shell integration initialization. <0>Learn more</0>"
		},
		"commandDelay": {
			"label": "Terminal command delay",
			"description": "Wait time in milliseconds after executing a command. <0>Learn more</0>"
		},
		"powershellCounter": {
			"label": "Enable PowerShell counter workaround",
			"description": "Adds a counter to PowerShell commands to improve capture. <0>Learn more</0>"
		},
		"zshClearEolMark": {
			"label": "Clear ZSH end-of-line mark",
			"description": "Clears PROMPT_EOL_MARK in zsh to avoid parsing issues. <0>Learn more</0>"
		},
		"zshOhMy": {
			"label": "Enable Oh My Zsh integration",
			"description": "Sets integration env variable. May require IDE restart. <0>Learn more</0>"
		},
		"zshP10k": {
			"label": "Enable Powerlevel10k integration",
			"description": "Sets integration env variable. <0>Learn more</0>"
		},
		"zdotdir": {
			"label": "Enable ZDOTDIR handling",
			"description": "Create a temporary dir for ZDOTDIR for proper zsh integration. <0>Learn more</0>"
		}
	},
	"advanced": {
		"diff": {
			"label": "Enable diff-based editing",
			"description": "Allow faster edits via diffs.",
			"matchPrecision": {
				"label": "Match precision",
				"description": "Controls how strictly code blocks must match when applying diffs."
			}
		}
	},
	"providers": {
		"apiProvider": "API Provider",
		"providerDocumentation": "Provider Documentation",
		"anthropicApiKey": "Anthropic API Key",
		"apiKeyStorageNotice": "Your API key is stored locally and never sent to our servers.",
		"getAnthropicApiKey": "Get Anthropic API Key",
		"useCustomBaseUrl": "Use custom base URL",
		"model": "Model",
		"validation": { "apiKey": "API key is required" },
		"placeholders": { "apiKey": "Enter your API key" },
		"rateLimitSeconds": { "label": "Rate limit", "description": "Minimum time between API requests." },
		"consecutiveMistakeLimit": {
			"label": "Consecutive mistake limit",
			"description": "Number of consecutive mistakes or repeats before showing the 'Having trouble' dialog",
			"unlimitedDescription": "Unlimited retries are enabled (auto-continue). The dialog will never appear.",
			"warning": "Setting 0 allows unlimited retries and may significantly increase API usage"
		},
		"openAiApiKey": "OpenAI API Key",
		"getOpenAiApiKey": "Get OpenAI API Key",
		"openAiBaseUrl": "Base URL",
		"apiKey": "API Key",
		"useLegacyFormat": "Use legacy OpenAI API format",
		"customHeaders": "Custom headers",
		"noCustomHeaders": "No custom headers defined. Click + to add.",
		"headerName": "Header name",
		"headerValue": "Header value",
		"setReasoningLevel": "Enable reasoning effort",
		"glamaApiKey": "Glama API Key",
		"getGlamaApiKey": "Get Glama API Key",
		"openRouterTransformsText": "Compress prompts and message chains to context size (<a>OpenRouter Transforms</a>)",
		"requestyApiKey": "Requesty API Key",
		"getRequestyApiKey": "Get Requesty API Key",
		"cerebrasApiKey": "Cerebras API Key",
		"getCerebrasApiKey": "Get Cerebras API Key",
		"chutesApiKey": "Chutes API Key",
		"getChutesApiKey": "Get Chutes API Key",
		"deepSeekApiKey": "DeepSeek API Key",
		"getDeepSeekApiKey": "Get DeepSeek API Key",
		"doubaoApiKey": "Doubao API Key",
		"getDoubaoApiKey": "Get Doubao API Key",
		"geminiApiKey": "Gemini API Key",
		"getGeminiApiKey": "Get Gemini API Key",
		"geminiParameters": {
			"urlContext": {
				"title": "Enable URL context",
				"description": "Allow Gemini to fetch and process URLs as additional context."
			},
			"groundingSearch": {
				"title": "Enable grounding via Google Search",
				"description": "Allow Gemini to search for up-to-date information and ground answers in real-time data."
			}
		},
		"googleCloudSetup": {
			"title": "To use Google Cloud Vertex AI:",
			"step1": "1. Create a Google Cloud account, enable Vertex AI API and required Claude models.",
			"step2": "2. Install Google Cloud CLI and configure default credentials.",
			"step3": "3. Or create a service account with a key."
		},
		"googleCloudCredentials": "Google Cloud credentials",
		"googleCloudKeyFile": "Google Cloud key file path",
		"googleCloudProjectId": "Google Cloud Project ID",
		"googleCloudRegion": "Google Cloud region",
		"lmStudio": {
			"baseUrl": "Base URL (optional)",
			"modelId": "Model ID",
			"speculativeDecoding": "Enable speculative decoding",
			"draftModelId": "Draft model ID",
			"draftModelDesc": "Draft model should be from the same family for speculative decoding to work well.",
			"selectDraftModel": "Select draft model",
			"noModelsFound": "No draft models found. Ensure LM Studio runs with server mode enabled.",
			"description": "LM Studio lets you run models locally. Read the <a>quick guide</a>. Also enable the LM Studio <b>local server</b> to work with this extension. <span>Note:</span> Researcherry uses complex prompts and works best with Claude; smaller models may behave poorly."
		},
		"ollama": {
			"baseUrl": "Base URL (optional)",
			"modelId": "Model ID",
			"description": "Ollama lets you run models locally. Read the quick guide.",
			"warning": "Note: Researcherry uses complex prompts and works best with Claude. Less capable models may not work well."
		},
		"litellmApiKey": "LiteLLM API Key",
		"litellmBaseUrl": "LiteLLM Base URL",
		"refreshModels": {
			"label": "Refresh models",
			"hint": "Please reopen settings to see the latest models.",
			"loading": "Refreshing models list...",
			"success": "Models list refreshed successfully!",
			"error": "Failed to refresh models. Please try again.",
			"missingConfig": "Please configure Base URL and API key first to refresh models."
		},
		"awsCrossRegion": "Use cross-region output",
		"awsBedrockVpc": {
			"useCustomVpcEndpoint": "Use custom VPC endpoint",
			"vpcEndpointUrlPlaceholder": "Enter VPC endpoint URL (optional)",
			"examples": "Examples:"
		},
		"awsCustomArnUse": "Enter a valid Amazon Bedrock ARN for the model used. Format examples:",
		"awsCustomArnDesc": "Ensure the region in the ARN matches the AWS region selected above.",
		"invalidArnFormat": "Invalid ARN format. Please check the examples above.",
		"huggingFaceApiKey": "Hugging Face API Key",
		"getHuggingFaceApiKey": "Get Hugging Face API Key",
		"huggingFaceModelId": "Model ID",
		"huggingFaceLoading": "Loading...",
		"huggingFaceModelsCount": "({{count}} models)",
		"huggingFaceSelectModel": "Select a model...",
		"huggingFaceSearchModels": "Search models...",
		"huggingFaceNoModelsFound": "No models found",
		"huggingFaceProvider": "Provider",
		"huggingFaceProviderAuto": "Auto",
		"huggingFaceSelectProvider": "Select a provider...",
		"huggingFaceSearchProviders": "Search providers...",
		"huggingFaceNoProvidersFound": "No providers found",
		"openRouter": {
			"providerRouting": {
				"title": "OpenRouter provider routing",
				"description": "OpenRouter routes requests to the best available providers for your selected model. You can also pin a specific provider.",
				"learnMore": "Learn more about provider routing"
			}
		},
		"customModel": {
			"capabilities": "Configure capabilities and pricing for your custom OpenAI-compatible model. Be careful when declaring capabilities, as it may affect Researcherry behavior.",
			"maxTokens": {
				"label": "Max output tokens",
				"description": "Maximum number of tokens the model can generate in a response. (-1 lets the server decide)"
			},
			"contextWindow": {
				"label": "Context window size",
				"description": "Total tokens (input + output) the model can process."
			},
			"imageSupport": { "label": "Image support", "description": "Whether the model can process images." },
			"computerUse": { "label": "Computer use", "description": "Whether the model can use a browser." },
			"promptCache": { "label": "Prompt cache", "description": "Whether the model supports prompt caching." },
			"pricing": {
				"input": {
					"label": "Input price",
					"description": "Price per million tokens in input messages/prompts."
				},
				"output": { "label": "Output price", "description": "Price per million tokens in model responses." },
				"cacheReads": {
					"label": "Cache read price",
					"description": "Price per million tokens when reading from cache."
				},
				"cacheWrites": {
					"label": "Cache write price",
					"description": "Price per million tokens when writing to cache."
				}
			},
			"resetDefaults": "Reset to default"
		}
	},
	"defaults": {
		"ollamaUrl": "Default: http://localhost:11434",
		"lmStudioUrl": "Default: http://localhost:1234",
		"geminiUrl": "Default: https://generativelanguage.googleapis.com"
	},
	"labels": { "customArn": "Custom ARN", "useCustomArn": "Use custom ARN..." },
	"placeholders": {
		"apiKey": "Enter API key...",
		"profileName": "Enter profile name",
		"accessKey": "Enter Access Key...",
		"secretKey": "Enter Secret Key...",
		"sessionToken": "Enter Session Token...",
		"credentialsJson": "Enter Credentials JSON...",
		"keyFilePath": "Enter key file path...",
		"projectId": "Enter Project ID...",
		"customArn": "Enter ARN (e.g., arn:aws:bedrock:us-east-1:123456789012:foundation-model/my-model)",
		"baseUrl": "Enter base URL...",
		"modelId": {
			"lmStudio": "e.g., meta-llama-3.1-8b-instruct",
			"lmStudioDraft": "e.g., lmstudio-community/llama-3.2-1b-instruct",
			"ollama": "e.g., llama3.1"
		},
		"numbers": {
			"maxTokens": "e.g., 4096",
			"contextWindow": "e.g., 128000",
			"inputPrice": "e.g., 0.0001",
			"outputPrice": "e.g., 0.0002",
			"cacheWritePrice": "e.g., 0.00005"
		}
	},
	"temperature": {
		"useCustom": "Use custom temperature",
		"description": "Controls randomness of model responses.",
		"rangeDescription": "Higher values are more random; lower are more deterministic."
	},
	"modelInfo": {
		"supportsImages": "Supports images",
		"noImages": "Does not support images",
		"supportsComputerUse": "Supports computer use",
		"noComputerUse": "Does not support computer use",
		"supportsPromptCache": "Supports prompt cache",
		"noPromptCache": "Does not support prompt cache",
		"maxOutput": "Max output",
		"inputPrice": "Input price",
		"outputPrice": "Output price",
		"cacheReadsPrice": "Cache reads price",
		"cacheWritesPrice": "Cache writes price",
		"enableR1Format": "Enable R1 model parameters",
		"enableR1FormatTips": "Enable when using R1 models to avoid 400 errors",
		"gemini": {
			"freeRequests": "* Free up to {{count}} requests per minute. Then pricing depends on prompt size.",
			"pricingDetails": "Pricing details.",
			"billingEstimate": "* Billing is an estimate; exact cost depends on prompt size."
		}
	},
	"modelPicker": {
		"label": "Model",
		"searchPlaceholder": "Search",
		"noMatchFound": "No match found",
		"useCustomModel": "Use custom: {{modelId}}",
		"automaticFetch": "The extension automatically fetches the latest models from <serviceLink>{{serviceName}}</serviceLink>. If unsure, Researcherry works best with <defaultModelLink>{{defaultModelId}}</defaultModelLink>. You can also search for 'free'."
	}
}
